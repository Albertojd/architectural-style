{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import numpy as np\n",
    "from keras.preprocessing import image\n",
    "import PIL\n",
    "import matplotlib.pyplot as plt\n",
    "import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D,MaxPool2D\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2564 images belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        brightness_range = [0.5,1.5],\n",
    "        horizontal_flip=True)\n",
    "training_set = train_datagen.flow_from_directory(\n",
    "        './data/train',\n",
    "        target_size=(64, 64),\n",
    "        batch_size=32,\n",
    "        class_mode='sparse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 400 images belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_set = test_datagen.flow_from_directory(\n",
    "        './data/val',\n",
    "        target_size=(64, 64),\n",
    "        batch_size=32,\n",
    "        class_mode='sparse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 62, 62, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 31, 31, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 29, 29, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 12, 12, 128)       73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 6, 6, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 4608)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               589952    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 4)                 516       \n",
      "=================================================================\n",
      "Total params: 683,716\n",
      "Trainable params: 683,716\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "#Block 1\n",
    "model.add(Conv2D(filters=32, kernel_size=3, activation='relu', input_shape=[64, 64, 3]))\n",
    "model.add(MaxPool2D(pool_size=2, strides=2))\n",
    "#Block 2\n",
    "model.add(Conv2D(filters=64, kernel_size=3, activation='relu'))\n",
    "model.add(MaxPool2D(pool_size=2, strides=2))\n",
    "#Block 3\n",
    "model.add(Conv2D(filters=128, kernel_size=3, activation='relu'))\n",
    "model.add(MaxPool2D(pool_size=2, strides=2))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(units=128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(4, activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer = 'adam', loss = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "    from_logits=False, reduction=\"auto\", name=\"sparse_categorical_crossentropy\"), metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "31/81 [==========>...................] - ETA: 34s - loss: 0.3590 - accuracy: 0.8672"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alber\\anaconda3\\lib\\site-packages\\PIL\\TiffImagePlugin.py:802: UserWarning: Corrupt EXIF data.  Expecting to read 4 bytes but only got 0. \n",
      "  warnings.warn(str(msg))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "81/81 [==============================] - 60s 735ms/step - loss: 0.3421 - accuracy: 0.8678 - val_loss: 0.2581 - val_accuracy: 0.8925\n",
      "Epoch 2/30\n",
      "81/81 [==============================] - 58s 721ms/step - loss: 0.3265 - accuracy: 0.8705 - val_loss: 0.1780 - val_accuracy: 0.9425\n",
      "Epoch 3/30\n",
      "81/81 [==============================] - 56s 695ms/step - loss: 0.3001 - accuracy: 0.8846 - val_loss: 0.2702 - val_accuracy: 0.8975\n",
      "Epoch 4/30\n",
      "81/81 [==============================] - 57s 705ms/step - loss: 0.3218 - accuracy: 0.8787 - val_loss: 0.2546 - val_accuracy: 0.9200\n",
      "Epoch 5/30\n",
      "81/81 [==============================] - 66s 815ms/step - loss: 0.3076 - accuracy: 0.8818 - val_loss: 0.2178 - val_accuracy: 0.9325\n",
      "Epoch 6/30\n",
      "81/81 [==============================] - 50s 622ms/step - loss: 0.3039 - accuracy: 0.8869 - val_loss: 0.2539 - val_accuracy: 0.8925\n",
      "Epoch 7/30\n",
      "81/81 [==============================] - 50s 612ms/step - loss: 0.2901 - accuracy: 0.8830 - val_loss: 0.1981 - val_accuracy: 0.9425\n",
      "Epoch 8/30\n",
      "81/81 [==============================] - 58s 722ms/step - loss: 0.2569 - accuracy: 0.9013 - val_loss: 0.1397 - val_accuracy: 0.9600\n",
      "Epoch 9/30\n",
      "81/81 [==============================] - 62s 762ms/step - loss: 0.2509 - accuracy: 0.8982 - val_loss: 0.1842 - val_accuracy: 0.9400\n",
      "Epoch 10/30\n",
      "81/81 [==============================] - 72s 887ms/step - loss: 0.2639 - accuracy: 0.8963 - val_loss: 0.1392 - val_accuracy: 0.9550\n",
      "Epoch 11/30\n",
      "81/81 [==============================] - 58s 718ms/step - loss: 0.2573 - accuracy: 0.8978 - val_loss: 0.1689 - val_accuracy: 0.9525\n",
      "Epoch 12/30\n",
      "81/81 [==============================] - 57s 700ms/step - loss: 0.2713 - accuracy: 0.8998 - val_loss: 0.1529 - val_accuracy: 0.9425\n",
      "Epoch 13/30\n",
      "81/81 [==============================] - 55s 678ms/step - loss: 0.2446 - accuracy: 0.9068 - val_loss: 0.1052 - val_accuracy: 0.9700\n",
      "Epoch 14/30\n",
      "81/81 [==============================] - 55s 682ms/step - loss: 0.2508 - accuracy: 0.8974 - val_loss: 0.1152 - val_accuracy: 0.9700\n",
      "Epoch 15/30\n",
      "81/81 [==============================] - 56s 696ms/step - loss: 0.2661 - accuracy: 0.8998 - val_loss: 0.1720 - val_accuracy: 0.9325\n",
      "Epoch 16/30\n",
      "81/81 [==============================] - 56s 695ms/step - loss: 0.2349 - accuracy: 0.9052 - val_loss: 0.1309 - val_accuracy: 0.9525\n",
      "Epoch 17/30\n",
      "81/81 [==============================] - 58s 716ms/step - loss: 0.2440 - accuracy: 0.9064 - val_loss: 0.1964 - val_accuracy: 0.9275\n",
      "Epoch 18/30\n",
      "81/81 [==============================] - 47s 584ms/step - loss: 0.2432 - accuracy: 0.9076 - val_loss: 0.0881 - val_accuracy: 0.9775\n",
      "Epoch 19/30\n",
      "81/81 [==============================] - 47s 584ms/step - loss: 0.2318 - accuracy: 0.9126 - val_loss: 0.0764 - val_accuracy: 0.9825\n",
      "Epoch 20/30\n",
      "81/81 [==============================] - 49s 602ms/step - loss: 0.2034 - accuracy: 0.9158 - val_loss: 0.0624 - val_accuracy: 0.9850\n",
      "Epoch 21/30\n",
      "81/81 [==============================] - 48s 588ms/step - loss: 0.2707 - accuracy: 0.8963 - val_loss: 0.0993 - val_accuracy: 0.9725\n",
      "Epoch 22/30\n",
      "81/81 [==============================] - 47s 580ms/step - loss: 0.2069 - accuracy: 0.9200 - val_loss: 0.3324 - val_accuracy: 0.8600\n",
      "Epoch 23/30\n",
      "81/81 [==============================] - 47s 583ms/step - loss: 0.2434 - accuracy: 0.9005 - val_loss: 0.1211 - val_accuracy: 0.9550\n",
      "Epoch 24/30\n",
      "81/81 [==============================] - 48s 589ms/step - loss: 0.2122 - accuracy: 0.9173 - val_loss: 0.1356 - val_accuracy: 0.9450\n",
      "Epoch 25/30\n",
      "81/81 [==============================] - 47s 581ms/step - loss: 0.2385 - accuracy: 0.9044 - val_loss: 0.1623 - val_accuracy: 0.9350\n",
      "Epoch 26/30\n",
      "81/81 [==============================] - 47s 579ms/step - loss: 0.2147 - accuracy: 0.9197 - val_loss: 0.0873 - val_accuracy: 0.9775\n",
      "Epoch 27/30\n",
      "81/81 [==============================] - 48s 592ms/step - loss: 0.2022 - accuracy: 0.9236 - val_loss: 0.1503 - val_accuracy: 0.9325\n",
      "Epoch 28/30\n",
      "81/81 [==============================] - 47s 581ms/step - loss: 0.2114 - accuracy: 0.9185 - val_loss: 0.0727 - val_accuracy: 0.9775\n",
      "Epoch 29/30\n",
      "81/81 [==============================] - 48s 594ms/step - loss: 0.1802 - accuracy: 0.9302 - val_loss: 0.0597 - val_accuracy: 0.9825\n",
      "Epoch 30/30\n",
      "81/81 [==============================] - 49s 600ms/step - loss: 0.1695 - accuracy: 0.9317 - val_loss: 0.0492 - val_accuracy: 0.9925\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1fb73130190>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x = training_set, validation_data = test_set, epochs = 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('./modelo/model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('./modelo/pesos.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
